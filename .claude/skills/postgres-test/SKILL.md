---
name: postgres-test
description: Automated PostgreSQL DB construction and SQL testing for immutable data models. Sets up PostgreSQL container with project-specific schema/data, executes all queries, and generates comprehensive test reports. Use when validating DDL generation results or testing query examples against real database. Triggers include "PostgreSQLã§æ¤œè¨¼", "SQLã‚’ãƒ†ã‚¹ãƒˆ", "ã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§å‹•ä½œç¢ºèª", "DDLã‚’æ¤œè¨¼".
---

# PostgreSQL DB Testing Skill

## Overview

Automate PostgreSQL database construction and SQL testing for immutable data model projects. This skill:
- Sets up isolated PostgreSQL containers per project
- Validates schema correctness (tables, constraints, indexes)
- Validates sample data integrity (row counts, FK relationships, chronological order)
- Executes all query examples automatically
- Generates comprehensive test reports in Markdown format

## Workflow

### Phase 0: Project Validation

**Objective**: Verify project exists and has required SQL files.

**Steps**:
1. Determine project name (from user input or context)
2. Verify `artifacts/{project-name}/` directory exists
3. Check for required files:
   - `schema.sql` - DDL definitions
   - `sample_data_relative.sql` - Sample data with relative dates
   - `query_examples.sql` - Query test suite

**If any file is missing**:
```
[ã‚¨ãƒ©ãƒ¼] å¿…é ˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project-name}
ä¸è¶³ã—ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:
- artifacts/{project-name}/schema.sql
- artifacts/{project-name}/sample_data_relative.sql
- artifacts/{project-name}/query_examples.sql

ã“ã‚Œã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚
```

**Output**: Validated project path

---

### Phase 1: PostgreSQL Environment Setup

**Objective**: Create isolated PostgreSQL container with project-specific SQL files.

**Execute Python script**:
```bash
python .claude/skills/postgres-test/scripts/postgres_manager.py setup {project-name}
```

**Script operations**:
1. **Stop existing container** (if exists): `cc-data-modeler-postgres-{project}`
2. **Remove old container and volumes** (clean slate)
3. **Start new PostgreSQL 16 container**:
   ```bash
   docker run -d \
     --name cc-data-modeler-postgres-{project} \
     -e POSTGRES_USER=datamodeler \
     -e POSTGRES_PASSWORD=datamodeler123 \
     -e POSTGRES_DB=immutable_model_db \
     -e TZ='Asia/Tokyo' \
     -p 5432:5432 \
     -v {absolute_path}/artifacts/{project}/schema.sql:/docker-entrypoint-initdb.d/01-schema.sql \
     -v {absolute_path}/artifacts/{project}/sample_data_relative.sql:/docker-entrypoint-initdb.d/02-sample_data.sql \
     postgres:16-alpine
   ```
4. **Wait for health check**: Poll `pg_isready` until ready (max 30 seconds)
5. **Verify connection**: Test database connection with simple query

**Success output**:
```
âœ… PostgreSQL container started successfully
   Container: cc-data-modeler-postgres-{project}
   Database: immutable_model_db
   Port: 5432
   Status: Healthy
```

**Error handling**:
- Port 5432 occupied â†’ Suggest stopping other containers
- Container startup timeout â†’ Show container logs
- SQL file mount error â†’ Verify file paths

**Output**: Connection parameters (host, port, database, credentials)

---

### Phase 2: Schema Validation

**Objective**: Verify DDL executed correctly and matches expectations.

**Execute validation queries**:

1. **Table count and list**:
```sql
SELECT table_name
FROM information_schema.tables
WHERE table_schema = 'public'
ORDER BY table_name;
```

2. **Column count per table**:
```sql
SELECT table_name, COUNT(*) as column_count
FROM information_schema.columns
WHERE table_schema = 'public'
GROUP BY table_name
ORDER BY table_name;
```

3. **Foreign key constraints**:
```sql
SELECT
    tc.constraint_name,
    tc.table_name,
    kcu.column_name,
    ccu.table_name AS foreign_table_name,
    ccu.column_name AS foreign_column_name
FROM information_schema.table_constraints AS tc
JOIN information_schema.key_column_usage AS kcu
  ON tc.constraint_name = kcu.constraint_name
JOIN information_schema.constraint_column_usage AS ccu
  ON ccu.constraint_name = tc.constraint_name
WHERE tc.constraint_type = 'FOREIGN KEY';
```

4. **Indexes**:
```sql
SELECT
    tablename,
    indexname,
    indexdef
FROM pg_indexes
WHERE schemaname = 'public'
ORDER BY tablename, indexname;
```

**Compare with model.json** (if available):
- Parse `artifacts/{project}/model.json`
- Extract expected entity count (resources + events + junctions)
- Compare expected vs actual table count
- Validate naming conventions (UPPER_SNAKE_CASE for tables)

**Validation results**:
```
### Schema Validation âœ…

**Tables**: Expected 21, Actual 21 âœ…
**Foreign Keys**: Expected 24, Actual 24 âœ…
**Indexes**: Expected 32, Actual 32 âœ…

| Table Name | Column Count | Status |
|------------|--------------|--------|
| PROJECT | 7 | âœ… |
| PERSON | 4 | âœ… |
| ORGANIZATION | 5 | âœ… |
...
```

**Output**: Schema validation section for report

---

### Phase 3: Data Validation

**Objective**: Verify sample data loaded correctly and maintains integrity.

**Execute validation queries**:

1. **Row counts per table**:
```sql
SELECT
    schemaname,
    tablename,
    n_live_tup as row_count
FROM pg_stat_user_tables
WHERE schemaname = 'public'
ORDER BY tablename;
```

2. **Foreign key integrity check**:
```sql
-- For each FK constraint, verify all references are valid
-- Dynamically generated based on schema validation results
```

3. **Event chronological order check** (for immutable model):
```sql
-- For each event table with datetime attribute:
SELECT
    MIN({datetime_column}) as first_event,
    MAX({datetime_column}) as last_event,
    COUNT(*) as event_count
FROM {event_table};

-- Verify: first_event < last_event
```

4. **Relative date verification**:
```sql
-- Check that dates are relative to current date
SELECT
    table_name,
    column_name,
    MIN(column_value) as oldest_date,
    MAX(column_value) as newest_date
FROM (
    -- Dynamically query all TIMESTAMP columns
) date_columns;

-- Verify: dates span past to future from current date
```

**Validation results**:
```
### Data Validation âœ…

**Row Counts**: All tables populated âœ…
**FK Integrity**: All foreign keys valid âœ…
**Chronological Order**: All events in correct time sequence âœ…

| Table Name | Row Count | Status |
|------------|-----------|--------|
| INDUSTRY | 3 | âœ… |
| CUSTOMER | 3 | âœ… |
| PROJECT | 3 | âœ… |
| PROJECT_START | 3 | âœ… |
...
```

**Output**: Data validation section for report

---

### Phase 4: Query Execution

**Objective**: Execute all queries from `query_examples.sql` and capture results.

**Parse query_examples.sql**:
```python
# Use comment markers to identify queries:
# -- ================================================
# -- ã€ã‚¯ã‚¨ãƒªNã€‘Query Title
# -- Description
# -- ================================================
# SELECT ...

queries = parse_query_file('artifacts/{project}/query_examples.sql')
# Returns: [
#   {
#     "id": 1,
#     "title": "ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ã¨ç¾åœ¨ã®çŠ¶æ…‹",
#     "description": "ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´: ã‚¤ãƒ™ãƒ³ãƒˆã‹ã‚‰ç¾åœ¨ã®çŠ¶æ…‹ã‚’é›†ç´„",
#     "sql": "SELECT ...",
#     "line_number": 10
#   },
#   ...
# ]
```

**Execute each query**:
```python
for query in queries:
    start_time = time.time()
    try:
        result = execute_query(query['sql'], connection)
        execution_time = (time.time() - start_time) * 1000  # ms

        query_result = {
            'id': query['id'],
            'title': query['title'],
            'status': 'success',
            'execution_time_ms': execution_time,
            'row_count': len(result.rows),
            'sample_rows': result.rows[:5],  # First 5 rows
            'columns': result.column_names
        }
    except Exception as e:
        query_result = {
            'id': query['id'],
            'title': query['title'],
            'status': 'error',
            'error_message': str(e),
            'error_line': extract_error_line(e)
        }
```

**Continue on failure**: If a query fails, capture error and continue with next query.

**Query execution results**:
```
### Query 1: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ã¨ç¾åœ¨ã®çŠ¶æ…‹ âœ…
**Execution Time**: 12ms
**Rows Returned**: 3

**Sample Results** (first 5 rows):
| ProjectID | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå | é¡§å®¢å | çŠ¶æ…‹ |
|-----------|---------------|--------|------|
| 1 | æ¬¡ä¸–ä»£ECã‚µã‚¤ãƒˆæ§‹ç¯‰ | æ ªå¼ä¼šç¤¾ãƒ†ãƒƒã‚¯ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ | å®Œäº† |
| 2 | å‹˜å®šç³»ã‚·ã‚¹ãƒ†ãƒ ãƒªãƒ—ãƒ¬ãƒ¼ã‚¹ | é‡‘èå¤ªéƒéŠ€è¡Œ | é€²è¡Œä¸­ |
| 3 | ç”Ÿç”£ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ æ”¹ä¿® | è£½é€ èŠ±å­å·¥æ¥­æ ªå¼ä¼šç¤¾ | é€²è¡Œä¸­ |

---

### Query 2: ç¾åœ¨ã®æ‹…å½“è€…ä¸€è¦§ âœ…
**Execution Time**: 18ms
**Rows Returned**: 5
...
```

**Output**: Query execution results with timing, row counts, sample data

---

### Phase 5: Report Generation

**Objective**: Generate comprehensive Markdown test report.

**Execute report generator**:
```bash
python .claude/skills/postgres-test/scripts/report_generator.py \
    --results results.json \
    --project {project-name} \
    --output artifacts/{project-name}/test_report.md
```

**Report structure**:

```markdown
# PostgreSQL Test Report

**Project**: {project-name}
**Date**: {timestamp}
**Status**: âœ… PASS | âŒ FAIL
**Container**: cc-data-modeler-postgres-{project}

---

## Executive Summary

- Total Queries: {count}
- Successful: {success_count}
- Failed: {fail_count}
- Total Execution Time: {total_time}ms
- Average Query Time: {avg_time}ms

---

## 1. Schema Validation

[Schema validation section from Phase 2]

---

## 2. Data Validation

[Data validation section from Phase 3]

---

## 3. Query Execution Results

[Query results from Phase 4]

---

## 4. Performance Analysis

| Query ID | Title | Execution Time | Rows | Performance |
|----------|-------|----------------|------|-------------|
| 1 | ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸€è¦§ | 12ms | 3 | âš¡ Fast |
| 2 | ç¾åœ¨ã®æ‹…å½“è€… | 18ms | 5 | âš¡ Fast |
| 7 | çµ„ç¹”éšå±¤ï¼ˆå†å¸°CTEï¼‰ | 234ms | 8 | âš ï¸ Slow |
...

**Performance Categories**:
- âš¡ Fast: < 50ms
- âœ… Normal: 50-100ms
- âš ï¸ Slow: 100-500ms
- ğŸ”´ Very Slow: > 500ms

**Slowest Queries**:
1. Query 7: çµ„ç¹”éšå±¤ï¼ˆå†å¸°CTEï¼‰ - 234ms
   - Recommendation: Add index on ORGANIZATION.ParentOrganizationID

---

## 5. Immutable Model Validation

### Event Sourcing Pattern âœ…
- All events have datetime attributes
- No UPDATE statements detected in queries
- State calculated from event aggregation

### Resource/Event Separation âœ…
- Resources: {resource_count} tables
- Events: {event_count} tables
- Junctions: {junction_count} tables

---

## Container Information

**Container**: cc-data-modeler-postgres-{project}
**Status**: Running
**Port**: 5432
**Database**: immutable_model_db
**User**: datamodeler

**To connect manually**:
```bash
docker exec -it cc-data-modeler-postgres-{project} psql -U datamodeler -d immutable_model_db
```

**To stop container**:
```bash
docker stop cc-data-modeler-postgres-{project}
docker rm cc-data-modeler-postgres-{project}
```

---

## Appendix: Test Environment

- PostgreSQL Version: 16 (Alpine)
- Test Date: {timestamp}
- Schema File: artifacts/{project}/schema.sql
- Data File: artifacts/{project}/sample_data_relative.sql
- Query File: artifacts/{project}/query_examples.sql
```

**Save report**:
- Primary: `artifacts/{project-name}/test_report.md`
- Display summary to user
- Prompt for cleanup action

**Output**: Test report file path

---

### Phase 6: Cleanup Prompt

**Ask user**:
```
ãƒ†ã‚¹ãƒˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚

ãƒ¬ãƒãƒ¼ãƒˆ: artifacts/{project-name}/test_report.md

PostgreSQLã‚³ãƒ³ãƒ†ãƒŠã®å‡¦ç†:
1. ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•ã—ãŸã¾ã¾ã«ã™ã‚‹ï¼ˆæ‰‹å‹•ã§æ¥ç¶šã—ã¦ã‚¯ã‚¨ãƒªã‚’è©¦ã›ã¾ã™ï¼‰
2. ã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢ã—ã¦å‰Šé™¤ã™ã‚‹

ç•ªå·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1ï¼‰:
```

**Option 1 (Keep running)**:
```
âœ… ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•ã—ãŸã¾ã¾ã«ã—ã¾ã—ãŸã€‚

æ¥ç¶šæƒ…å ±:
  docker exec -it cc-data-modeler-postgres-{project} psql -U datamodeler -d immutable_model_db

åœæ­¢ã™ã‚‹å ´åˆ:
  docker stop cc-data-modeler-postgres-{project}
```

**Option 2 (Cleanup)**:
```bash
python .claude/skills/postgres-test/scripts/postgres_manager.py cleanup {project-name}
```

```
âœ… ã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢ãƒ»å‰Šé™¤ã—ã¾ã—ãŸã€‚
```

---

## Error Handling

### Common Errors

**1. Port 5432 already in use**
```
[ã‚¨ãƒ©ãƒ¼] ãƒãƒ¼ãƒˆ5432ãŒæ—¢ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã¾ã™

è§£æ±ºæ–¹æ³•:
1. æ—¢å­˜ã®PostgreSQLã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢ã™ã‚‹:
   docker ps | grep postgres
   docker stop {container_name}

2. ã¾ãŸã¯ã€åˆ¥ã®ãƒãƒ¼ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ï¼ˆä»Šå¾Œã®æ©Ÿèƒ½ï¼‰
```

**2. SQL syntax error in schema.sql**
```
[ã‚¨ãƒ©ãƒ¼] ã‚¹ã‚­ãƒ¼ãƒå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ

Line 45: syntax error at or near "INAVLID"
  CREATE TABLE INAVLID_TABLE ...
               ^

artifacts/{project}/schema.sql ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚
```

**3. Container startup timeout**
```
[ã‚¨ãƒ©ãƒ¼] ã‚³ãƒ³ãƒ†ãƒŠã®èµ·å‹•ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ30ç§’çµŒéï¼‰

ã‚³ãƒ³ãƒ†ãƒŠãƒ­ã‚°:
  docker logs cc-data-modeler-postgres-{project}

ä¸€èˆ¬çš„ãªåŸå› :
- ãƒ¡ãƒ¢ãƒªä¸è¶³
- ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ä¸è¶³
- Dockerãƒ‡ãƒ¼ãƒ¢ãƒ³ãŒå¿œç­”ã—ã¦ã„ãªã„
```

**4. Query timeout**
```
[è­¦å‘Š] ã‚¯ã‚¨ãƒª{N}ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ5åˆ†çµŒéï¼‰

ã‚¯ã‚¨ãƒª: {title}
SQL: {first_100_chars}...

ã“ã®ã‚¯ã‚¨ãƒªã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç¶šè¡Œã—ã¾ã™ã€‚
```

---

## Reference Files

This skill includes detailed reference documentation:

- **[docker-operations.md](references/docker-operations.md)** - Docker container management patterns, volume mounting, health checks
- **[validation-patterns.md](references/validation-patterns.md)** - SQL validation query templates for schema and data verification
- **[troubleshooting.md](references/troubleshooting.md)** - Common issues and solutions for PostgreSQL testing

Read these as needed during testing for detailed guidance.

---

## Script Usage

### Manual Script Execution

If needed, scripts can be run independently:

**Setup container**:
```bash
cd .claude/skills/postgres-test/scripts
python postgres_manager.py setup project-record-system
```

**Run queries**:
```bash
python postgres_manager.py execute \
    --project project-record-system \
    --query-file artifacts/project-record-system/query_examples.sql
```

**Generate report**:
```bash
python report_generator.py \
    --results results.json \
    --project project-record-system \
    --output artifacts/project-record-system/test_report.md
```

**Cleanup**:
```bash
python postgres_manager.py cleanup project-record-system
```

---

## Multi-Project Support

Test multiple projects sequentially:
```bash
python postgres_manager.py test-all \
    --projects invoice-management,project-record-system
```

Each project gets its own container:
- `cc-data-modeler-postgres-invoice-management`
- `cc-data-modeler-postgres-project-record-system`

---

## Notes

- Always use `sample_data_relative.sql` (not `sample_data.sql`) for consistent relative date testing
- Container names are project-specific to allow parallel testing
- Reports are saved in each project's artifacts directory
- Query execution continues even if individual queries fail
- Performance analysis helps identify slow queries for optimization
