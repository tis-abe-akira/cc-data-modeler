#!/usr/bin/env python3
"""
Classifier - Knowledge Source
ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ãƒªã‚½ãƒ¼ã‚¹ã¨ã‚¤ãƒ™ãƒ³ãƒˆã«åˆ†é¡
"""

import json
import yaml
from pathlib import Path


def classify_entities(raw_entities: dict) -> dict:
    """
    ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ãƒªã‚½ãƒ¼ã‚¹ã¨ã‚¤ãƒ™ãƒ³ãƒˆã«åˆ†é¡
    
    å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Claude APIã‚’å‘¼ã³å‡ºã—ã¦åˆ†é¡ã—ã¾ã™ã€‚
    """
    
    classification_prompt = f"""
ä»¥ä¸‹ã®ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å€™è£œã‚’ã€ã‚¤ãƒŸãƒ¥ãƒ¼ã‚¿ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã®åŸå‰‡ã«åŸºã¥ã„ã¦
ãƒªã‚½ãƒ¼ã‚¹ã¨ã‚¤ãƒ™ãƒ³ãƒˆã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚

ã€ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å€™è£œã€‘
{json.dumps(raw_entities, ensure_ascii=False, indent=2)}

ã€åˆ†é¡åŸºæº–ã€‘

1. **ãƒªã‚½ãƒ¼ã‚¹ï¼ˆResourceï¼‰**
   - ç¶™ç¶šçš„ã«å­˜åœ¨ã™ã‚‹ã‚‚ã®
   - æ™‚é–“çµŒéã§çŠ¶æ…‹ãŒå¤‰åŒ–ã—ã†ã‚‹ã‚‚ã®
   - ä¾‹: é¡§å®¢ã€å•†å“ã€ç¤¾å“¡ã€å¥‘ç´„

2. **ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆEventï¼‰**
   - ç‰¹å®šæ™‚ç‚¹ã§ç™ºç”Ÿã—ãŸäº‹å®Ÿ
   - ä¸€åº¦ç™ºç”Ÿã—ãŸã‚‰å¤‰æ›´ã•ã‚Œãªã„
   - **å¿…ãš1ã¤ã®æ—¥æ™‚å±æ€§ã‚’æŒã¤**ï¼ˆé‡è¦ï¼‰
   - ä¾‹: æ³¨æ–‡ã€å…¥é‡‘ã€å‡ºè·ã€é€ä»˜

3. **éš ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆã®æ¤œå‡º**
   - ãƒªã‚½ãƒ¼ã‚¹ã«ã€Œæ›´æ–°æ—¥æ™‚ã€ãŒã‚ã‚‹å ´åˆã€èƒŒå¾Œã«ã‚¤ãƒ™ãƒ³ãƒˆãŒéš ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§
   - ä¾‹: ç¤¾å“¡æƒ…å ±ã®æ›´æ–°æ—¥æ™‚ â†’ ç¤¾å“¡ç•°å‹•ã‚¤ãƒ™ãƒ³ãƒˆ

ã€å‡ºåŠ›å½¢å¼ã€‘
å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

{{
  "resources": [
    {{
      "japanese": "é¡§å®¢",
      "english": "Customer",
      "attributes": ["é¡§å®¢ID", "é¡§å®¢å", "ä½æ‰€"],
      "note": "åˆ†é¡ç†ç”±"
    }}
  ],
  "events": [
    {{
      "japanese": "è«‹æ±‚æ›¸é€ä»˜",
      "english": "InvoiceSend",
      "datetime_attribute": "é€ä»˜æ—¥æ™‚",
      "attributes": ["é€ä»˜æ—¥æ™‚", "é€ä»˜æ–¹æ³•"],
      "related_resource": "Customer",
      "note": "åˆ†é¡ç†ç”±"
    }}
  ],
  "hidden_events": [
    {{
      "japanese": "ç™ºè¦‹ã•ã‚ŒãŸéš ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆå",
      "english": "HiddenEvent",
      "datetime_attribute": "ã‚¤ãƒ™ãƒ³ãƒˆæ—¥æ™‚",
      "trigger_resource": "å…ƒã®ãƒªã‚½ãƒ¼ã‚¹å",
      "note": "æ¤œå‡ºç†ç”±"
    }}
  ]
}}
"""
    
    print("=" * 60)
    print("ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£åˆ†é¡ä¸­...")
    print("=" * 60)
    
    # ã‚µãƒ³ãƒ—ãƒ«å®Ÿè£…
    result = {
        "resources": [
            {
                "japanese": "é¡§å®¢",
                "english": "Customer",
                "attributes": ["é¡§å®¢ID", "é¡§å®¢å", "ä½æ‰€", "é›»è©±ç•ªå·", "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹"],
                "note": "è«‹æ±‚æ›¸ã‚’å—ã‘å–ã‚‹ä¸»ä½“ã€ç¶™ç¶šçš„ã«å­˜åœ¨ã™ã‚‹"
            }
        ],
        "events": [
            {
                "japanese": "è«‹æ±‚æ›¸é€ä»˜",
                "english": "InvoiceSend",
                "datetime_attribute": "é€ä»˜æ—¥æ™‚",
                "attributes": ["é€ä»˜æ—¥æ™‚", "é€ä»˜æ–¹æ³•", "è«‹æ±‚æ›¸ç•ªå·"],
                "related_resource": "Customer",
                "note": "ç‰¹å®šæ™‚ç‚¹ã§ç™ºç”Ÿã—ãŸé€ä»˜è¡Œç‚º"
            },
            {
                "japanese": "ç¢ºèªçŠ¶é€ä»˜",
                "english": "ConfirmationSend",
                "datetime_attribute": "é€ä»˜æ—¥æ™‚",
                "attributes": ["é€ä»˜æ—¥æ™‚", "é€ä»˜æ–¹æ³•"],
                "related_resource": "Customer",
                "note": "æœªå…¥é‡‘æ™‚ã«ç™ºç”Ÿã™ã‚‹é€ä»˜è¡Œç‚º"
            },
            {
                "japanese": "å…¥é‡‘",
                "english": "Payment",
                "datetime_attribute": "å…¥é‡‘æ—¥æ™‚",
                "attributes": ["å…¥é‡‘æ—¥æ™‚", "å…¥é‡‘é¡", "å…¥é‡‘æ–¹æ³•"],
                "related_resource": "Customer",
                "note": "ç‰¹å®šæ™‚ç‚¹ã§ç™ºç”Ÿã—ãŸæ”¯æ‰•ã„è¡Œç‚º"
            }
        ],
        "hidden_events": []
    }
    
    return result


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    
    blackboard_path = Path("/tmp/data-modeler-blackboard")
    
    # å‰æ®µéšã®å‡ºåŠ›ã‚’èª­ã¿è¾¼ã¿
    input_file = blackboard_path / "entities_raw.json"
    
    if not input_file.exists():
        print("âŒ ã‚¨ãƒ©ãƒ¼: entities_raw.jsonãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        print("   entity-extractorã‚’å…ˆã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return 1
    
    with open(input_file, "r", encoding="utf-8") as f:
        raw_entities = json.load(f)
    
    print(f"ğŸ“¥ å…¥åŠ›: {len(raw_entities.get('noun_candidates', []))}å€‹ã®åè©å€™è£œ")
    
    # åˆ†é¡å®Ÿè¡Œ
    result = classify_entities(raw_entities)
    
    # çµæœã‚’ãƒ–ãƒ©ãƒƒã‚¯ãƒœãƒ¼ãƒ‰ã«ä¿å­˜
    output_file = blackboard_path / "entities_classified.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… åˆ†é¡å®Œäº†:")
    print(f"   - ãƒªã‚½ãƒ¼ã‚¹: {len(result['resources'])}å€‹")
    print(f"   - ã‚¤ãƒ™ãƒ³ãƒˆ: {len(result['events'])}å€‹")
    print(f"   - éš ã‚ŒãŸã‚¤ãƒ™ãƒ³ãƒˆ: {len(result.get('hidden_events', []))}å€‹")
    print(f"   - å‡ºåŠ›å…ˆ: {output_file}")
    
    # è©³ç´°è¡¨ç¤º
    print("\nğŸ“‹ ãƒªã‚½ãƒ¼ã‚¹:")
    for r in result['resources']:
        print(f"   - {r['japanese']} ({r['english']})")
    
    print("\nğŸ“‹ ã‚¤ãƒ™ãƒ³ãƒˆ:")
    for e in result['events']:
        print(f"   - {e['japanese']} ({e['english']}) - æ—¥æ™‚å±æ€§: {e['datetime_attribute']}")
    
    # çŠ¶æ…‹ã‚’æ›´æ–°
    state_file = blackboard_path / "state.yaml"
    with open(state_file, "r", encoding="utf-8") as f:
        state = yaml.safe_load(f)
    
    if "classification" not in state.get("completed_phases", []):
        state.setdefault("completed_phases", []).append("classification")
    state["current_phase"] = "relationship_analysis"
    state["next_action"] = "relationship-analyzer"
    
    with open(state_file, "w", encoding="utf-8") as f:
        yaml.dump(state, f, allow_unicode=True)
    
    print(f"\nğŸ“Š æ¬¡ã®ãƒ•ã‚§ãƒ¼ã‚º: {state['current_phase']}")
    print(f"   å®Ÿè¡Œã™ã‚‹Knowledge Source: {state['next_action']}")
    
    return 0


if __name__ == "__main__":
    exit(main())
